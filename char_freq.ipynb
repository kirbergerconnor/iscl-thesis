{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, re, pandas as pd, numpy as np\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import naive_bayes, svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = ['Esperanto.txt', 'Interlingua.txt', 'Lojban.txt', 'Lfn.txt', 'Russian.txt', 'English.txt', 'German.txt', 'Japanese.txt', 'Mandarin.txt', 'Hindi.txt']\n",
    "natural = ['Russian.txt', 'German.txt', 'English.txt', 'Japanese.txt', 'Mandarin.txt', 'Hindi.txt']\n",
    "constructed = ['Esperanto.txt', 'Interlingua.txt', 'Lojban.txt', 'Lfn.txt']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using character frequency distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_frequency(corpus, limit=None):\n",
    "    with open(corpus) as f:\n",
    "        if limit:\n",
    "            text = f.read().splitlines()[:int(limit / len(corpora))]\n",
    "        else:\n",
    "            text = f.read().splitlines()\n",
    "        f.close()\n",
    "    df = pd.DataFrame(columns=['Char', 'Act_Freq', 'Rel_Freq', 'Zipf_Freq'])\n",
    "    frequencies = Counter(char for line in text for char in line if char.split())\n",
    "    frequencies = frequencies.most_common()\n",
    "    top_frequency = frequencies[0][1]\n",
    "    \n",
    "    for index, item in enumerate(frequencies, start=1):\n",
    "        relative_freq = \"1/{}\".format(index)\n",
    "        zipf_freq = top_frequency * (1/index)\n",
    "        df.loc[index] = [item[0], item[1], relative_freq, zipf_freq]\n",
    "    return df\n",
    "\n",
    "\n",
    "def char_vocabulary(corpus=None, df=None, limit=None):\n",
    "    if corpus:\n",
    "        df = char_frequency(corpus, limit=limit)\n",
    "    return {char: freq for char, freq in zip(df['Char'], df['Act_Freq'])}\n",
    "\n",
    "\n",
    "def plot_char_dist(corpus):\n",
    "    df = char_frequency(corpus=corpus, df=None, limit=None)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.ylabel('Zipf Frequency')\n",
    "    plt.xlabel('Char')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.bar(df['Char'], df['Zipf_Freq'])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def corpus_lengths(corpora):\n",
    "    lengths = {}\n",
    "    for file in corpora:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            data = f.read().splitlines()\n",
    "            f.close()\n",
    "        lengths[f'{file.split(\".\")[0]}'] = len(data)\n",
    "    return lengths\n",
    "\n",
    "\n",
    "def vocab_sizes(corpora):\n",
    "    sizes = {}\n",
    "    for file in corpora:\n",
    "        vocab = char_vocabulary(corpus=file, df=None, limit=None)\n",
    "        sizes[f'{file.split(\".\")[0]}'] = len(vocab)\n",
    "    return sizes\n",
    "    \n",
    "    \n",
    "def obfuscate_label_text(corpus, vocab):\n",
    "    with open(corpus, 'r', encoding='utf-8') as f:\n",
    "        # Labeling the data for binary classification, 0 for Natlang and 1 for Conlang\n",
    "        if corpus in natural:\n",
    "            text = f.read().splitlines()\n",
    "            label = [0] * len(text)\n",
    "            labeled = list(zip(text, label))\n",
    "        elif corpus in constructed:\n",
    "            text = f.read().splitlines()\n",
    "            label = [1] * len(text)\n",
    "            labeled = list(zip(text, label))\n",
    "        f.close()\n",
    "    # Char-based frequency mapping of characters in each string    \n",
    "    mapping = {value: chr(97 + i) for i, value in enumerate(vocab.values())}\n",
    "    vocab = {k: mapping[v] for k, v in vocab.items()}\n",
    "    table = str.maketrans(vocab)\n",
    "    obfuscated = [(line[0].translate(table), line[1]) for line in labeled]\n",
    "    return obfuscated\n",
    "\n",
    "\n",
    "# def one_hot_encode(data, vocab):\n",
    "#     seq_length = max(len(line[0] for line in data))\n",
    "#     string_encoded = np.zeros((seq_length, len(vocab)), dtype=np.float32)\n",
    "#     for string, label in data:\n",
    "#         for i, char in enumerate(string):\n",
    "#             if i >= seq_length:\n",
    "#                 break\n",
    "#             string_encoded[i][vocab[char]] = 1\n",
    "#         label_encoded = np.array([label], dtype=np.int64)\n",
    "#     return string_encoded, label_encoded\n",
    "\n",
    "\n",
    "def preprocess_text(corpora, limit=None):\n",
    "    data = []\n",
    "    for corpus in corpora:\n",
    "        vocab = char_vocabulary(corpus=corpus, df=None, limit=limit)\n",
    "        data.extend(obfuscate_label_text(corpus=corpus, vocab=vocab))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_text(corpora, limit=100000)\n",
    "text, labels = [d[0] for d in data], [d[1] for d in data]\n",
    "vectorizer = CountVectorizer(analyzer='char')\n",
    "vectorizer.fit(text)\n",
    "text = vectorizer.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(text, labels, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifying using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 483.62, NNZs: 571, Bias: -1.930660, T: 10000, Avg. loss: 171.696578\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 294.83, NNZs: 670, Bias: -1.394658, T: 10000, Avg. loss: 31.843293\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 217.72, NNZs: 787, Bias: -1.090127, T: 10000, Avg. loss: 19.308277\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 171.48, NNZs: 889, Bias: -0.791514, T: 10000, Avg. loss: 13.971323\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 149.21, NNZs: 974, Bias: -0.568083, T: 10000, Avg. loss: 10.667529\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 131.01, NNZs: 1083, Bias: -0.385974, T: 10000, Avg. loss: 8.216275\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 119.12, NNZs: 1166, Bias: -0.235999, T: 10000, Avg. loss: 7.601711\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 108.87, NNZs: 1238, Bias: -0.110418, T: 10000, Avg. loss: 6.014324\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 99.32, NNZs: 1312, Bias: 0.013231, T: 10000, Avg. loss: 6.222599\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 93.82, NNZs: 1380, Bias: 0.128730, T: 10000, Avg. loss: 5.430491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 89.10, NNZs: 1456, Bias: 0.210238, T: 10000, Avg. loss: 4.460869\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 82.62, NNZs: 1505, Bias: 0.301549, T: 10000, Avg. loss: 4.153679\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 77.70, NNZs: 1553, Bias: 0.378095, T: 10000, Avg. loss: 4.001848\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 73.03, NNZs: 1594, Bias: 0.452083, T: 10000, Avg. loss: 3.396329\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 70.92, NNZs: 1660, Bias: 0.530663, T: 10000, Avg. loss: 3.225112\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 67.70, NNZs: 1698, Bias: 0.600081, T: 10000, Avg. loss: 3.294464\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 64.66, NNZs: 1744, Bias: 0.645615, T: 10000, Avg. loss: 2.803238\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 61.03, NNZs: 1808, Bias: 0.696327, T: 10000, Avg. loss: 2.631913\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 59.45, NNZs: 1854, Bias: 0.769103, T: 10000, Avg. loss: 2.551643\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 57.45, NNZs: 1907, Bias: 0.811823, T: 10000, Avg. loss: 2.350076\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 55.06, NNZs: 1956, Bias: 0.854358, T: 10000, Avg. loss: 2.146708\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 53.44, NNZs: 2033, Bias: 0.891937, T: 10000, Avg. loss: 2.069410\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 51.53, NNZs: 2072, Bias: 0.943910, T: 10000, Avg. loss: 1.958872\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 51.12, NNZs: 2114, Bias: 0.968961, T: 10000, Avg. loss: 2.060409\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 49.50, NNZs: 2153, Bias: 1.002158, T: 10000, Avg. loss: 1.975239\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 48.14, NNZs: 2178, Bias: 1.054795, T: 10000, Avg. loss: 1.779663\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 46.33, NNZs: 2217, Bias: 1.083529, T: 10000, Avg. loss: 1.879329\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 45.22, NNZs: 2258, Bias: 1.112704, T: 10000, Avg. loss: 1.762341\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 44.41, NNZs: 2288, Bias: 1.146705, T: 10000, Avg. loss: 1.784440\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 43.40, NNZs: 2322, Bias: 1.178151, T: 10000, Avg. loss: 1.692461\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 42.43, NNZs: 2353, Bias: 1.201751, T: 10000, Avg. loss: 1.646915\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 41.73, NNZs: 2380, Bias: 1.238297, T: 10000, Avg. loss: 1.413104\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 40.72, NNZs: 2410, Bias: 1.263211, T: 10000, Avg. loss: 1.382257\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 39.94, NNZs: 2444, Bias: 1.291912, T: 10000, Avg. loss: 1.446847\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 39.23, NNZs: 2472, Bias: 1.313738, T: 10000, Avg. loss: 1.226870\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 38.39, NNZs: 2508, Bias: 1.330181, T: 10000, Avg. loss: 1.377419\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 37.92, NNZs: 2538, Bias: 1.356773, T: 10000, Avg. loss: 1.251713\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 37.27, NNZs: 2569, Bias: 1.375912, T: 10000, Avg. loss: 1.379498\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.86, NNZs: 2609, Bias: 1.391365, T: 10000, Avg. loss: 1.143574\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 36.05, NNZs: 2629, Bias: 1.406851, T: 10000, Avg. loss: 1.183295\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 35.47, NNZs: 2658, Bias: 1.424106, T: 10000, Avg. loss: 1.228735\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 35.18, NNZs: 2688, Bias: 1.436786, T: 10000, Avg. loss: 1.101767\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 34.50, NNZs: 2713, Bias: 1.457227, T: 10000, Avg. loss: 1.040624\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 34.04, NNZs: 2742, Bias: 1.469533, T: 10000, Avg. loss: 1.039699\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 33.53, NNZs: 2761, Bias: 1.485355, T: 10000, Avg. loss: 1.139478\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 32.90, NNZs: 2806, Bias: 1.498586, T: 10000, Avg. loss: 1.068561\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 32.50, NNZs: 2834, Bias: 1.510609, T: 10000, Avg. loss: 1.080993\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 32.17, NNZs: 2863, Bias: 1.522175, T: 10000, Avg. loss: 1.034578\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 31.91, NNZs: 2884, Bias: 1.534262, T: 10000, Avg. loss: 0.901277\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 31.46, NNZs: 2908, Bias: 1.543976, T: 10000, Avg. loss: 0.965382\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 30.95, NNZs: 2926, Bias: 1.561468, T: 10000, Avg. loss: 0.872386\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 30.78, NNZs: 2937, Bias: 1.568507, T: 10000, Avg. loss: 0.976949\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 30.15, NNZs: 2952, Bias: 1.575446, T: 10000, Avg. loss: 0.909784\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 29.70, NNZs: 2990, Bias: 1.589838, T: 10000, Avg. loss: 0.798725\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 29.31, NNZs: 3009, Bias: 1.597344, T: 10000, Avg. loss: 0.788408\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 28.88, NNZs: 3037, Bias: 1.612575, T: 10000, Avg. loss: 0.809583\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 28.54, NNZs: 3064, Bias: 1.620163, T: 10000, Avg. loss: 0.740041\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 28.37, NNZs: 3084, Bias: 1.628791, T: 10000, Avg. loss: 0.857294\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 27.88, NNZs: 3099, Bias: 1.637818, T: 10000, Avg. loss: 0.772220\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 27.63, NNZs: 3119, Bias: 1.645677, T: 10000, Avg. loss: 0.748639\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 27.56, NNZs: 3138, Bias: 1.652148, T: 10000, Avg. loss: 0.774679\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 27.38, NNZs: 3156, Bias: 1.664406, T: 10000, Avg. loss: 0.754218\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 27.19, NNZs: 3180, Bias: 1.676041, T: 10000, Avg. loss: 0.804672\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 26.94, NNZs: 3206, Bias: 1.679885, T: 10000, Avg. loss: 0.679870\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 26.60, NNZs: 3225, Bias: 1.684230, T: 10000, Avg. loss: 0.727407\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 26.34, NNZs: 3240, Bias: 1.692019, T: 10000, Avg. loss: 0.747176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 26.15, NNZs: 3254, Bias: 1.695014, T: 10000, Avg. loss: 0.819752\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 25.93, NNZs: 3276, Bias: 1.699883, T: 10000, Avg. loss: 0.670558\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 25.57, NNZs: 3300, Bias: 1.706609, T: 10000, Avg. loss: 0.739040\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 25.33, NNZs: 3323, Bias: 1.710090, T: 10000, Avg. loss: 0.695463\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 25.10, NNZs: 3334, Bias: 1.716562, T: 10000, Avg. loss: 0.704410\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.81, NNZs: 3357, Bias: 1.723663, T: 10000, Avg. loss: 0.664666\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.40, NNZs: 3384, Bias: 1.725618, T: 10000, Avg. loss: 0.594052\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.14, NNZs: 3400, Bias: 1.729953, T: 10000, Avg. loss: 0.625653\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.99, NNZs: 3419, Bias: 1.734745, T: 10000, Avg. loss: 0.548328\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.84, NNZs: 3437, Bias: 1.737619, T: 10000, Avg. loss: 0.679091\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.93, NNZs: 3452, Bias: 1.741085, T: 10000, Avg. loss: 0.603585\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.69, NNZs: 3471, Bias: 1.745100, T: 10000, Avg. loss: 0.646515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.54, NNZs: 3483, Bias: 1.747283, T: 10000, Avg. loss: 0.584675\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.46, NNZs: 3508, Bias: 1.751563, T: 10000, Avg. loss: 0.607593\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.26, NNZs: 3523, Bias: 1.754504, T: 10000, Avg. loss: 0.594311\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 23.09, NNZs: 3546, Bias: 1.756198, T: 10000, Avg. loss: 0.615817\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.91, NNZs: 3562, Bias: 1.756933, T: 10000, Avg. loss: 0.580171\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.64, NNZs: 3574, Bias: 1.762577, T: 10000, Avg. loss: 0.530090\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.51, NNZs: 3584, Bias: 1.765633, T: 10000, Avg. loss: 0.520318\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.43, NNZs: 3600, Bias: 1.765650, T: 10000, Avg. loss: 0.555272\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.28, NNZs: 3620, Bias: 1.769770, T: 10000, Avg. loss: 0.504048\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 22.22, NNZs: 3641, Bias: 1.770724, T: 10000, Avg. loss: 0.535207\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 21.99, NNZs: 3663, Bias: 1.774493, T: 10000, Avg. loss: 0.487802\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 21.78, NNZs: 3679, Bias: 1.776286, T: 10000, Avg. loss: 0.521374\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 21.66, NNZs: 3697, Bias: 1.780614, T: 10000, Avg. loss: 0.553246\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 21.60, NNZs: 3712, Bias: 1.786083, T: 10000, Avg. loss: 0.462978\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 21.52, NNZs: 3727, Bias: 1.788144, T: 10000, Avg. loss: 0.491321\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 21.42, NNZs: 3742, Bias: 1.792072, T: 10000, Avg. loss: 0.541344\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 21.29, NNZs: 3758, Bias: 1.793195, T: 10000, Avg. loss: 0.492616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 21.17, NNZs: 3780, Bias: 1.794271, T: 10000, Avg. loss: 0.484931\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 21.03, NNZs: 3796, Bias: 1.798946, T: 10000, Avg. loss: 0.493955\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 20.81, NNZs: 3805, Bias: 1.801729, T: 10000, Avg. loss: 0.464836\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 20.66, NNZs: 3818, Bias: 1.803140, T: 10000, Avg. loss: 0.470095\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 20.54, NNZs: 3827, Bias: 1.805721, T: 10000, Avg. loss: 0.483285\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 20.41, NNZs: 3842, Bias: 1.805324, T: 10000, Avg. loss: 0.480133\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 20.30, NNZs: 3857, Bias: 1.807811, T: 10000, Avg. loss: 0.439893\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 20.23, NNZs: 3876, Bias: 1.808954, T: 10000, Avg. loss: 0.451610\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 20.06, NNZs: 3886, Bias: 1.812697, T: 10000, Avg. loss: 0.489911\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.94, NNZs: 3901, Bias: 1.817468, T: 10000, Avg. loss: 0.422049\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.92, NNZs: 3911, Bias: 1.819672, T: 10000, Avg. loss: 0.461023\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.73, NNZs: 3928, Bias: 1.820757, T: 10000, Avg. loss: 0.464145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.71, NNZs: 3936, Bias: 1.820967, T: 10000, Avg. loss: 0.460290\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.51, NNZs: 3951, Bias: 1.819794, T: 10000, Avg. loss: 0.458559\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.54, NNZs: 3962, Bias: 1.820949, T: 10000, Avg. loss: 0.481118\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.37, NNZs: 3971, Bias: 1.821341, T: 10000, Avg. loss: 0.469454\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.26, NNZs: 3984, Bias: 1.823148, T: 10000, Avg. loss: 0.418259\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.27, NNZs: 4000, Bias: 1.823570, T: 10000, Avg. loss: 0.416827\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.14, NNZs: 4009, Bias: 1.825381, T: 10000, Avg. loss: 0.438357\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 19.05, NNZs: 4019, Bias: 1.824107, T: 10000, Avg. loss: 0.472683\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.97, NNZs: 4040, Bias: 1.824253, T: 10000, Avg. loss: 0.417110\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.85, NNZs: 4051, Bias: 1.823511, T: 10000, Avg. loss: 0.428360\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.81, NNZs: 4065, Bias: 1.824335, T: 10000, Avg. loss: 0.377458\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.60, NNZs: 4074, Bias: 1.825237, T: 10000, Avg. loss: 0.385120\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.51, NNZs: 4080, Bias: 1.825244, T: 10000, Avg. loss: 0.427618\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.43, NNZs: 4099, Bias: 1.824229, T: 10000, Avg. loss: 0.384770\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.27, NNZs: 4112, Bias: 1.824902, T: 10000, Avg. loss: 0.412020\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.28, NNZs: 4121, Bias: 1.824691, T: 10000, Avg. loss: 0.377339\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.22, NNZs: 4131, Bias: 1.825685, T: 10000, Avg. loss: 0.413325\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.13, NNZs: 4148, Bias: 1.827654, T: 10000, Avg. loss: 0.364252\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.07, NNZs: 4165, Bias: 1.829929, T: 10000, Avg. loss: 0.403318\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.94, NNZs: 4169, Bias: 1.829431, T: 10000, Avg. loss: 0.397822\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.89, NNZs: 4183, Bias: 1.828899, T: 10000, Avg. loss: 0.366007\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.80, NNZs: 4203, Bias: 1.829560, T: 10000, Avg. loss: 0.386877\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.80, NNZs: 4216, Bias: 1.828170, T: 10000, Avg. loss: 0.418089\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.69, NNZs: 4234, Bias: 1.829029, T: 10000, Avg. loss: 0.388536\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.63, NNZs: 4242, Bias: 1.829507, T: 10000, Avg. loss: 0.383990\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.52, NNZs: 4257, Bias: 1.830757, T: 10000, Avg. loss: 0.366711\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.46, NNZs: 4264, Bias: 1.829885, T: 10000, Avg. loss: 0.375122\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.37, NNZs: 4276, Bias: 1.832329, T: 10000, Avg. loss: 0.354900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.31, NNZs: 4295, Bias: 1.832680, T: 10000, Avg. loss: 0.369974\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.23, NNZs: 4308, Bias: 1.833121, T: 10000, Avg. loss: 0.337130\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.21, NNZs: 4316, Bias: 1.833220, T: 10000, Avg. loss: 0.334755\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.10, NNZs: 4322, Bias: 1.834497, T: 10000, Avg. loss: 0.337775\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 17.00, NNZs: 4334, Bias: 1.836991, T: 10000, Avg. loss: 0.338497\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.96, NNZs: 4349, Bias: 1.838721, T: 10000, Avg. loss: 0.341925\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.84, NNZs: 4356, Bias: 1.838774, T: 10000, Avg. loss: 0.344056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.79, NNZs: 4366, Bias: 1.837568, T: 10000, Avg. loss: 0.353118\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.79, NNZs: 4382, Bias: 1.837486, T: 10000, Avg. loss: 0.350774\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.70, NNZs: 4393, Bias: 1.839955, T: 10000, Avg. loss: 0.333176\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.67, NNZs: 4404, Bias: 1.839373, T: 10000, Avg. loss: 0.376491\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.61, NNZs: 4415, Bias: 1.839989, T: 10000, Avg. loss: 0.357029\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.53, NNZs: 4419, Bias: 1.838985, T: 10000, Avg. loss: 0.341870\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.53, NNZs: 4430, Bias: 1.840094, T: 10000, Avg. loss: 0.314773\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.47, NNZs: 4441, Bias: 1.841886, T: 10000, Avg. loss: 0.343503\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.41, NNZs: 4448, Bias: 1.841776, T: 10000, Avg. loss: 0.342989\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.33, NNZs: 4467, Bias: 1.843022, T: 10000, Avg. loss: 0.321589\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.30, NNZs: 4475, Bias: 1.843238, T: 10000, Avg. loss: 0.356254\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.29, NNZs: 4484, Bias: 1.843060, T: 10000, Avg. loss: 0.328452\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.18, NNZs: 4492, Bias: 1.844027, T: 10000, Avg. loss: 0.324235\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.15, NNZs: 4505, Bias: 1.844262, T: 10000, Avg. loss: 0.310411\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.12, NNZs: 4518, Bias: 1.843578, T: 10000, Avg. loss: 0.310014\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.07, NNZs: 4530, Bias: 1.844435, T: 10000, Avg. loss: 0.325955\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.03, NNZs: 4541, Bias: 1.845398, T: 10000, Avg. loss: 0.315051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 16.00, NNZs: 4546, Bias: 1.845209, T: 10000, Avg. loss: 0.321968\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.94, NNZs: 4557, Bias: 1.843726, T: 10000, Avg. loss: 0.324956\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.88, NNZs: 4565, Bias: 1.843265, T: 10000, Avg. loss: 0.340998\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.91, NNZs: 4576, Bias: 1.840725, T: 10000, Avg. loss: 0.327164\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.79, NNZs: 4583, Bias: 1.839254, T: 10000, Avg. loss: 0.339845\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.76, NNZs: 4591, Bias: 1.838016, T: 10000, Avg. loss: 0.312180\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.68, NNZs: 4600, Bias: 1.837693, T: 10000, Avg. loss: 0.321760\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.64, NNZs: 4604, Bias: 1.837062, T: 10000, Avg. loss: 0.309904\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.55, NNZs: 4612, Bias: 1.837978, T: 10000, Avg. loss: 0.314287\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.52, NNZs: 4618, Bias: 1.838426, T: 10000, Avg. loss: 0.322264\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.51, NNZs: 4624, Bias: 1.839614, T: 10000, Avg. loss: 0.279984\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.50, NNZs: 4636, Bias: 1.839544, T: 10000, Avg. loss: 0.309602\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.46, NNZs: 4644, Bias: 1.839218, T: 10000, Avg. loss: 0.337547\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.38, NNZs: 4652, Bias: 1.838737, T: 10000, Avg. loss: 0.341042\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.30, NNZs: 4659, Bias: 1.837936, T: 10000, Avg. loss: 0.296659\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.29, NNZs: 4676, Bias: 1.836421, T: 10000, Avg. loss: 0.306877\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.25, NNZs: 4688, Bias: 1.836618, T: 10000, Avg. loss: 0.307917\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.22, NNZs: 4694, Bias: 1.837048, T: 10000, Avg. loss: 0.263561\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.21, NNZs: 4703, Bias: 1.835408, T: 10000, Avg. loss: 0.312377\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.22, NNZs: 4709, Bias: 1.834968, T: 10000, Avg. loss: 0.347662\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.14, NNZs: 4718, Bias: 1.835567, T: 10000, Avg. loss: 0.293243\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.08, NNZs: 4730, Bias: 1.835913, T: 10000, Avg. loss: 0.273518\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.07, NNZs: 4737, Bias: 1.836001, T: 10000, Avg. loss: 0.292912\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 15.04, NNZs: 4743, Bias: 1.836806, T: 10000, Avg. loss: 0.308982\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 14.95, NNZs: 4753, Bias: 1.836388, T: 10000, Avg. loss: 0.312465\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 14.95, NNZs: 4765, Bias: 1.835873, T: 10000, Avg. loss: 0.282297\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 14.90, NNZs: 4776, Bias: 1.835875, T: 10000, Avg. loss: 0.299181\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 14.88, NNZs: 4784, Bias: 1.835435, T: 10000, Avg. loss: 0.265123\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 14.84, NNZs: 4792, Bias: 1.835639, T: 9928, Avg. loss: 0.285626\n",
      "Total training time: 0.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier(loss=\"log_loss\", tol=1e-3, verbose=1, random_state=42, validation_fraction=0.1)\n",
    "batch_size = 10000\n",
    "num_batches = x_train.shape[0] // batch_size + 1\n",
    "\n",
    "# Training\n",
    "for i in range(num_batches):\n",
    "    start = i * batch_size\n",
    "    end = min((i + 1) * batch_size, x_train.shape[0])\n",
    "    batch_x, batch_y = x_train[start:end], y_train[start:end]\n",
    "    # batch_x = vectorizer.transform(batch_x)\n",
    "    clf.partial_fit(batch_x, batch_y, classes=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9304228672587461\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "accuracy = clf.score(x_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifying Using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
