{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try first with English corpus\n",
    "with open('./current_corpora/en_wiki_extractor.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    \n",
    "# Encode text\n",
    "chars = tuple(set(text))\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "encoded = np.array([char2int[ch] for ch in text])\n",
    "\n",
    "\n",
    "# One hot encode\n",
    "def one_hot_encode(arr, n_labels):\n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "# Batches\n",
    "def get_batches(arr, n_seqs, n_steps):\n",
    "    '''Create a generator that returns batches of size n_seqs x n_steps from arr.\n",
    "    \n",
    "        Args\n",
    "        ----\n",
    "        arr: Array to make batches from\n",
    "        n_seqs: Batch size, number of sequences per batch\n",
    "        n_steps: Number of sequence steps per batch\n",
    "    '''\n",
    "    \n",
    "    batch_size = n_seqs * n_steps\n",
    "    n_batches = len(arr)//batch_size\n",
    "    \n",
    "    # Make only full batches\n",
    "    arr = arr[:n_batches * batch_size]\n",
    "    \n",
    "    # Reshape into n_seqs rows\n",
    "    arr = arr.reshape((n_seqs, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        \n",
    "        # Features\n",
    "        x = arr[:, n:n+n_steps]\n",
    "        \n",
    "        # Targets, shifted by 1\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+n_steps]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "            \n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, tokens, n_steps=100, n_hidden=256, n_layers=2, \n",
    "                 drop_prob=0.5, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        # Creating char dictionaries\n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        \n",
    "        # Define LSTM\n",
    "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # Define dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        # Define fully connected output layer\n",
    "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.init_weights()\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hc):\n",
    "        ''' Forward pass. Inputs are `x` and hidden/cell state are `hc`. '''\n",
    "        \n",
    "        # Get x and new hidden state (h, c) from LSTM\n",
    "        x, (h, c) = self.lstm(x, hc)\n",
    "        \n",
    "        # Pass x through dropout layer\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Stack up LSTM outputs\n",
    "        x = x.reshape(x.size()[0]*x.size()[1], self.n_hidden)\n",
    "        \n",
    "        # Put x through fc layer\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Return x and hidden state (h, c)\n",
    "        return x, (h, c)\n",
    "    \n",
    "    \n",
    "    def predict(self, device, char, h=None, top_k=None):\n",
    "        ''' Given a character, predict the next character.\n",
    "            \n",
    "            Returns predicted character and hidden state.\n",
    "        '''\n",
    "        \n",
    "        self.to(device)\n",
    "            \n",
    "        if h is None:\n",
    "            h = self.init_hidden(1)\n",
    "            \n",
    "        x = np.array([[self.char2int[char]]])\n",
    "        x = one_hot_encode(x, len(self.chars))\n",
    "        inputs = torch.from_numpy(x).to(device)\n",
    "            \n",
    "        h = tuple([each.data for each in h])\n",
    "        out, h = self.forward(inputs, h)\n",
    "        p = F.softmax(out, dim=1).data.cpu()\n",
    "        \n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(self.chars))\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "            \n",
    "        return self.int2char[char], h\n",
    "    \n",
    "    def init_weights(self):\n",
    "        ''' Initialize weights for fc layer '''\n",
    "        \n",
    "        initrange = 0.1\n",
    "        \n",
    "        # Set bias tensor to all zeros\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        # FC weights as random uniform\n",
    "        self.fc.weight.data.uniform_(-1, 1)\n",
    "        \n",
    "    def init_hidden(self, n_seqs):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x n_seqs x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(self.n_layers, n_seqs, self.n_hidden).zero_(),\n",
    "                weight.new(self.n_layers, n_seqs, self.n_hidden).zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model (without Cross Validation)\n",
    "\n",
    "# def train(net, device, data, epochs=10, n_seqs=10, n_steps=50, lr=0.001, clip=5, val_frac=0.1, cuda=False, print_every=10):\n",
    "#     ''' Training a network\n",
    "    \n",
    "#         Args\n",
    "#         ----\n",
    "#         net: CharRNN network\n",
    "#         device: CPU or GPU (cuda)\n",
    "#         data: text data to train on\n",
    "#         epochs: Number of epochs to train\n",
    "#         n_seqs: Number of sequences per batch (batch size)\n",
    "#         n_steps: Number of character steps per batch\n",
    "#         lr: learning rate\n",
    "#         clip: gradient clipping\n",
    "#         val_frac: Validation data as fraction\n",
    "#         cuda: Using CUDA on a GPU\n",
    "#         print_every: Number of steps for printing training/validation loss\n",
    "#     '''\n",
    "    \n",
    "#     net.train()\n",
    "    \n",
    "#     opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "#     # Split training/validation data\n",
    "#     val_idx = int(len(data)*(1-val_frac))\n",
    "#     data, val_data = data[:val_idx], data[val_idx:]\n",
    "    \n",
    "#     net.to(device)\n",
    "        \n",
    "#     counter = 0\n",
    "#     n_chars = len(net.chars)\n",
    "    \n",
    "#     for e in range(epochs):\n",
    "#         h = net.init_hidden(n_seqs)\n",
    "        \n",
    "#         for x, y in get_batches(data, n_seqs, n_steps):\n",
    "#             counter += 1\n",
    "            \n",
    "#             # One-hot encode our data and make them Torch tensors\n",
    "#             x = one_hot_encode(x, n_chars)\n",
    "#             inputs, targets = torch.from_numpy(x).to(device), torch.from_numpy(y).to(device)\n",
    "\n",
    "#             # Creating new variables for the hidden state, otherwise\n",
    "#             # we'd backprop through the entire training history\n",
    "#             h = tuple([each.data for each in h])\n",
    "\n",
    "#             net.zero_grad()\n",
    "#             output, h = net.forward(inputs, h)\n",
    "#             loss = criterion(output, targets.view(n_seqs*n_steps).type(torch.LongTensor))\n",
    "#             loss.backward()\n",
    "            \n",
    "#             # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "#             nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "\n",
    "#             opt.step()\n",
    "            \n",
    "#             if counter % print_every == 0:\n",
    "                \n",
    "#                 # Get validation loss\n",
    "#                 val_h = net.init_hidden(n_seqs)\n",
    "#                 val_losses = []\n",
    "                \n",
    "#                 for x, y in get_batches(val_data, n_seqs, n_steps):\n",
    "                    \n",
    "#                     # One-hot encode our data and make them Torch tensors\n",
    "#                     x = one_hot_encode(x, n_chars)\n",
    "#                     inputs, targets = torch.from_numpy(x).to(device), torch.from_numpy(y).to(device)\n",
    "                    \n",
    "#                     # Creating new variables for the hidden state, otherwise\n",
    "#                     # we'd backprop through the entire training history\n",
    "#                     val_h = tuple([each.data for each in val_h])\n",
    "                    \n",
    "#                     output, val_h = net.forward(inputs, val_h)\n",
    "#                     val_loss = criterion(output, targets.view(n_seqs*n_steps).type(torch.LongTensor))\n",
    "                \n",
    "#                     val_losses.append(val_loss.item())\n",
    "                \n",
    "#                 print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "#                       \"Step: {}...\".format(counter),\n",
    "#                       \"Loss: {:.4f}...\".format(loss.item()),\n",
    "#                       \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
    "                \n",
    "\n",
    "# net = CharRNN(chars, n_hidden=512, n_layers=2)\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train without Cross Validation\n",
    "\n",
    "# # Hyperparams\n",
    "# n_seqs = 2480\n",
    "# n_steps = 100\n",
    "# n_folds = 5\n",
    "# epochs = 10\n",
    "# lr = 0.001\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# train(net, device, encoded, n_folds=n_folds, epochs=epochs, n_seqs=n_seqs, n_steps=n_steps, lr=lr, clip=5, cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharRNN(\n",
      "  (lstm): LSTM(28, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=28, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Train the model (with Cross Validation)        \n",
    "def train(net, device, data, n_folds=5, epochs=10, n_seqs=10, n_steps=50, lr=0.001, clip=5):\n",
    "    ''' Training a network\n",
    "    \n",
    "        Args\n",
    "        ----\n",
    "        net: CharRNN network\n",
    "        device: CPU or GPU (cuda)\n",
    "        data: text data to train on\n",
    "        n_folds: Number of folds for cross-validation\n",
    "        epochs: Number of epochs to train\n",
    "        n_seqs: Number of sequences per batch (batch size)\n",
    "        n_steps: Number of character steps per batch\n",
    "        lr: learning rate\n",
    "        clip: gradient clipping\n",
    "    '''\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    n_chars = len(net.chars)\n",
    "    \n",
    "    net.to(device)\n",
    "        \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(data)):\n",
    "        \n",
    "        train_data, val_data = data[train_idx], data[val_idx]\n",
    "    \n",
    "        for e in range(epochs):\n",
    "            h = net.init_hidden(n_seqs)\n",
    "          \n",
    "            for x, y in get_batches(train_data, n_seqs, n_steps):\n",
    "              \n",
    "                # One hot encode and convert to Torch tensors\n",
    "                x = one_hot_encode(x, n_chars)\n",
    "                inputs, targets = torch.from_numpy(x).to(device), torch.from_numpy(y).to(device)\n",
    "\n",
    "                # Create new variables for the hidden state to avoid backprop\n",
    "                # through the entire training history\n",
    "                h = tuple([each.data for each in h])\n",
    "\n",
    "                net.zero_grad()\n",
    "                output, h = net.forward(inputs, h)\n",
    "                loss = criterion(output, targets.view(n_seqs*n_steps).type(torch.LongTensor))\n",
    "\n",
    "                loss.backward()\n",
    "                \n",
    "                # `clip_grad_norm` to avoid exploding gradient\n",
    "                nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "\n",
    "                opt.step()\n",
    "              \n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                \"Loss: {:.4f}...\".format(loss.item()))\n",
    "          \n",
    "        # Evaluate on validation data\n",
    "        val_losses = []\n",
    "        val_h = net.init_hidden(n_seqs)\n",
    "        net.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, y in get_batches(val_data, n_seqs, n_steps):\n",
    "                x = one_hot_encode(x, len(net.chars))\n",
    "                x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                    \n",
    "                # Create new variables for the hidden state to avoid backprop\n",
    "                # through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                \n",
    "                inputs, targets = x.to(device), y.to(device)                \n",
    "                output, val_h = net.forward(inputs, val_h)\n",
    "                val_loss = criterion(output, targets.view(n_seqs * n_steps).type(torch.LongTensor))\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "        val_loss = np.mean(val_losses)\n",
    "        val_perplexity = torch.exp(val_loss)\n",
    "        \n",
    "        print(\"Fold: {}/{}...\".format(fold + 1, n_folds),\n",
    "            \"Validation Loss: {:.4f}...\".format(val_loss.item()),\n",
    "            \"Validation Perplexity: {:.4f}\".format(val_perplexity.item()))\n",
    "\n",
    "\n",
    "net = CharRNN(chars, n_hidden=512, n_layers=2)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m lr \u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m\n\u001b[1;32m      9\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m train(net, device, encoded, n_folds\u001b[39m=\u001b[39;49mn_folds, epochs\u001b[39m=\u001b[39;49mepochs, n_seqs\u001b[39m=\u001b[39;49mn_seqs, n_steps\u001b[39m=\u001b[39;49mn_steps, lr\u001b[39m=\u001b[39;49mlr, clip\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[11], line 45\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, device, data, n_folds, epochs, n_seqs, n_steps, lr, clip)\u001b[0m\n\u001b[1;32m     42\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([each\u001b[39m.\u001b[39mdata \u001b[39mfor\u001b[39;00m each \u001b[39min\u001b[39;00m h])\n\u001b[1;32m     44\u001b[0m net\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 45\u001b[0m output, h \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39;49mforward(inputs, h)\n\u001b[1;32m     46\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, targets\u001b[39m.\u001b[39mview(n_seqs\u001b[39m*\u001b[39mn_steps)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mLongTensor))\n\u001b[1;32m     48\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[3], line 34\u001b[0m, in \u001b[0;36mCharRNN.forward\u001b[0;34m(self, x, hc)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m\u001b[39m\u001b[39m''' Forward pass. Inputs are `x` and hidden/cell state are `hc`. '''\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m# Get x and new hidden state (h, c) from LSTM\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m x, (h, c) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, hc)\n\u001b[1;32m     36\u001b[0m \u001b[39m# Pass x through dropout layer\u001b[39;00m\n\u001b[1;32m     37\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/rnn.py:774\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    773\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    775\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    776\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    777\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    778\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train with Cross Validation\n",
    "\n",
    "# Hyperparams\n",
    "n_seqs = 2480\n",
    "n_steps = 100\n",
    "n_folds = 5\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train(net, device, encoded, n_folds=n_folds, epochs=epochs, n_seqs=n_seqs, n_steps=n_steps, lr=lr, clip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "\n",
    "# model_name = 'char_rnn.net'\n",
    "\n",
    "# checkpoint = {'n_hidden': net.n_hidden,\n",
    "#               'n_layers': net.n_layers,\n",
    "#               'state_dict': net.state_dict(),\n",
    "#               'tokens': net.chars}\n",
    "\n",
    "# with open(model_name, 'wb') as f:\n",
    "#     torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test/Sample model\n",
    "\n",
    "# def sample(net, device, size, prime='The', top_k=None):\n",
    "     \n",
    "#     net.to(device)\n",
    "#     net.eval()\n",
    "    \n",
    "#     # Run through the prime chars\n",
    "#     chars = [ch for ch in prime]\n",
    "    \n",
    "#     h = net.init_hidden(1)\n",
    "#     for ch in prime:\n",
    "#         char, h = net.predict(device, ch, h, top_k=top_k)\n",
    "\n",
    "#     chars.append(char)\n",
    "    \n",
    "#     # Pass prev char and get new one\n",
    "#     for ii in range(size):\n",
    "#         char, h = net.predict(device, chars[-1], h, top_k=top_k)\n",
    "#         chars.append(char)\n",
    "\n",
    "#     return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained model\n",
    "\n",
    "# with open('modelname.net', 'rb') as f:\n",
    "#     checkpoint = torch.load(f)\n",
    "    \n",
    "# loaded = CharRNN(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
    "# loaded.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# print(sample(loaded, device, 2000, top_k=5, prime=\"Example text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
