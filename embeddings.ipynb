{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random, numpy as np, seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from sklearn.manifold import TSNE\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('German.txt', 'r', encoding='utf-8') as f:\n",
    "    sentences = f.read().splitlines()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary:  33\n",
      "Int to Char:  ['<PAD>', '<UNK>', 't', 'y', 'x', 'g', 'u', 'ü', 'h', 'd', 'b', 'v', 'j', 'ö', 'l', ' ', 'r', 'n', 'i', 'o', 'm', 'w', 'p', 'c', 'z', 'e', 's', 'ä', 'q', 'ß', 'k', 'a', 'f']\n",
      "Char to Int:  {'<PAD>': 0, '<UNK>': 1, 't': 2, 'y': 3, 'x': 4, 'g': 5, 'u': 6, 'ü': 7, 'h': 8, 'd': 9, 'b': 10, 'v': 11, 'j': 12, 'ö': 13, 'l': 14, ' ': 15, 'r': 16, 'n': 17, 'i': 18, 'o': 19, 'm': 20, 'w': 21, 'p': 22, 'c': 23, 'z': 24, 'e': 25, 's': 26, 'ä': 27, 'q': 28, 'ß': 29, 'k': 30, 'a': 31, 'f': 32}\n"
     ]
    }
   ],
   "source": [
    "class CharVocab: \n",
    "    ''' Create a Vocabulary for '''\n",
    "    def __init__(self, type_vocab,pad_token='<PAD>', eos_token='<EOS>', unk_token='<UNK>'): \n",
    "        self.type = type_vocab\n",
    "        #self.int2char ={}\n",
    "        self.int2char = []\n",
    "        if pad_token !=None:\n",
    "            self.int2char += [pad_token]\n",
    "        if eos_token !=None:\n",
    "            self.int2char += [eos_token]\n",
    "        if unk_token !=None:\n",
    "            self.int2char += [unk_token]\n",
    "        #self.int2char[1]=eos_token\n",
    "        #self.int2char[2]=unk_token\n",
    "        self.char2int = {}\n",
    "        \n",
    "    def __call__(self, text):       \n",
    "        chars = set(''.join(text))\n",
    "        # Dictionary mapping integers to the characters\n",
    "        self.int2char += list(chars)\n",
    "        # Dictionary mapping characters to integers\n",
    "        self.char2int = {char: ind for ind, char in enumerate(self.int2char)}\n",
    "\n",
    "vocab = CharVocab('char','<PAD>',None,'<UNK>')\n",
    "vocab(sentences)\n",
    "print('Length of vocabulary: ', len(vocab.int2char))\n",
    "print('Int to Char: ', vocab.int2char)\n",
    "print('Char to Int: ', vocab.char2int)\n",
    "\n",
    "vocab = vocab.char2int\n",
    "\n",
    "class MaskedSequenceDataset(Dataset):\n",
    "    def __init__(self, sentences, vocab, mask_ratio=0.2):\n",
    "        self.sentences = sentences\n",
    "        self.vocab = vocab\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.vocab_size = len(vocab)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.sentences[index]\n",
    "        sequence = [self.vocab.get(c) for c in sentence]\n",
    "\n",
    "        # mask some of the characters in the sequence\n",
    "        num_masked = int(len(sequence) * self.mask_ratio)\n",
    "        masked_indices = torch.randperm(len(sequence))[:num_masked]\n",
    "        masked_sequence = sequence.copy()\n",
    "        for i in masked_indices:\n",
    "            masked_sequence[i] = self.vocab.get('<UNK>')\n",
    "\n",
    "        return torch.LongTensor(masked_sequence), torch.LongTensor(sequence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Char Embeddings with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(sentences))\n",
    "test_size = len(sentences) - train_size\n",
    "train_sentences, test_sentences = torch.utils.data.random_split(sentences, [train_size, test_size])\n",
    "\n",
    "# define the collate function for the dataloader\n",
    "def collate_fn(batch):\n",
    "    inputs = [torch.LongTensor(b[0]) for b in batch]\n",
    "    targets = [torch.LongTensor(b[1]) for b in batch]\n",
    "    inputs = pad_sequence(inputs, batch_first=True, padding_value=vocab.get('<PAD>'))\n",
    "    targets = pad_sequence(targets, batch_first=True, padding_value=-100)\n",
    "    return inputs, targets\n",
    "\n",
    "train_dataset = MaskedSequenceDataset(train_sentences, vocab)\n",
    "test_dataset = MaskedSequenceDataset(test_sentences, vocab)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pad_sequence(): argument 'padding_value' (position 3) must be float, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     21\u001b[0m     train_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mfor\u001b[39;00m batch_inputs, batch_targets \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[1;32m     23\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     25\u001b[0m         logits \u001b[39m=\u001b[39m model(batch_inputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      7\u001b[0m inputs \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mLongTensor(b[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m batch]\n\u001b[1;32m      8\u001b[0m targets \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mLongTensor(b[\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m batch]\n\u001b[0;32m----> 9\u001b[0m inputs \u001b[39m=\u001b[39m pad_sequence(inputs, batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, padding_value\u001b[39m=\u001b[39;49mvocab\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39m<PAD>\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     10\u001b[0m targets \u001b[39m=\u001b[39m pad_sequence(targets, batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, padding_value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39mreturn\u001b[39;00m inputs, targets\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/utils/rnn.py:398\u001b[0m, in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    394\u001b[0m         sequences \u001b[39m=\u001b[39m sequences\u001b[39m.\u001b[39munbind(\u001b[39m0\u001b[39m)\n\u001b[1;32m    396\u001b[0m \u001b[39m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[39m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mpad_sequence(sequences, batch_first, padding_value)\n",
      "\u001b[0;31mTypeError\u001b[0m: pad_sequence(): argument 'padding_value' (position 3) must be float, not NoneType"
     ]
    }
   ],
   "source": [
    "class MaskedLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(MaskedLanguageModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embedded = self.embedding(inputs)\n",
    "        outputs, _ = self.rnn(embedded)\n",
    "        logits = self.fc(outputs)\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "model = MaskedLanguageModel(len(vocab), embedding_dim=128, hidden_dim=256)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    for batch_inputs, batch_targets in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(batch_inputs)\n",
    "        loss = criterion(logits.view(-1, len(vocab)), batch_targets.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.embedding.weight.detach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def one_hot_encode(indices, dict_size):\n",
    "#     ''' Define one hot encode matrix for our sequences'''\n",
    "#     # Creating a multi-dimensional array with the desired output shape\n",
    "#     # Encode every integer with its one hot representation\n",
    "#     features = np.eye(dict_size, dtype=np.float32)[indices.flatten()]\n",
    "    \n",
    "#     # Finally reshape it to get back to the original array\n",
    "#     features = features.reshape((*indices.shape, dict_size))\n",
    "            \n",
    "#     return features\n",
    "\n",
    "# def encode_text(input_text, vocab, one_hot=False, masking=False, padding=False):\n",
    "#     total_len = sum(len(s) for s in input_text)\n",
    "#     avg_len = int(total_len/len(input_text))\n",
    "#     mask_chars = 5\n",
    "#     output = []\n",
    "#     for seq in input_text:\n",
    "#         seq = [vocab.char2int.get(c,0) for c in seq]\n",
    "#         # seq.append(vocab.char2int.get('<EOS>'))\n",
    "#         if masking:\n",
    "#             mask_indices = random.sample(range(len(seq)), mask_chars)\n",
    "#             for i in mask_indices:\n",
    "#                 seq[i] = vocab.char2int.get('<UNK>')\n",
    "#         if padding:\n",
    "#             if len(seq) < avg_len:\n",
    "#                 pads = [vocab.char2int.get('<PAD>')] * (avg_len - (len(seq)))\n",
    "#                 seq.extend(pads)\n",
    "#             elif len(seq) > avg_len:\n",
    "#                 seq = seq[:avg_len]   \n",
    "#         output.append(seq)\n",
    "    \n",
    "#     if one_hot:\n",
    "#     # One hot encode every integer of the sequence\n",
    "#         dict_size = len(vocab.char2int)\n",
    "#         return one_hot_encode(output, dict_size)\n",
    "#     else:\n",
    "#         return np.array(output)\n",
    "     \n",
    "# train_data = encode_text(sentences, vocab, one_hot=False, masking=True, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "model.eval()\n",
    "\n",
    "input_seq = 'der schnelle braune Fuchs springt über den faulen Hund'\n",
    "masked_char = '*'\n",
    "x = torch.tensor([char_to_index[c] for c in input_seq]).unsqueeze(0)\n",
    "\n",
    "mask_tensor = torch.tensor([1 if c == '*' else 0 for c in input_seq], dtype=torch.bool)\n",
    "mask_index = mask_tensor.nonzero()[0].item()\n",
    "mask_tensor[mask_index] = 1\n",
    "\n",
    "y_pred = model(x, mask_tensor)\n",
    "pred_index = y_pred.argmax(dim=2)\n",
    "next_char = index_to_char[pred_index[0][mask_index].item()]\n",
    "\n",
    "print(f\"Given the sequence '{input_seq}', the predicted masked character is '{next_char}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "embeddings_tsne = tsne.fit_transform(embeddings)\n",
    "\n",
    "plt.scatter(embeddings_tsne[:,0], embeddings_tsne[:,1])\n",
    "for i, char in enumerate(unique_chars):\n",
    "    plt.annotate(char, (embeddings_tsne[i,0], embeddings_tsne[i,1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Char Embeddings with FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(sentences))\n",
    "test_size = len(sentences) - train_size\n",
    "train_sentences, test_sentences = torch.utils.data.random_split(sentences, [train_size, test_size])\n",
    "\n",
    "# define the collate function for the dataloader\n",
    "def collate_fn(batch):\n",
    "    # inputs = [torch.tensor([vocab[c] for c in seq[:-n]], dtype=torch.long) for seq, n in batch]\n",
    "    # targets = [torch.tensor([vocab[c] for c in seq[n:]], dtype=torch.long) for seq, n in batch]\n",
    "    inputs = [torch.LongTensor(b[0]) for b in batch]\n",
    "    targets = [torch.LongTensor(b[1]) for b in batch]\n",
    "    inputs = pad_sequence(inputs, batch_first=True, padding_value=-1)\n",
    "    targets = pad_sequence(targets, batch_first=True, padding_value=-100)\n",
    "    return inputs, targets\n",
    "\n",
    "train_dataset = MaskedSequenceDataset(train_sentences, vocab)\n",
    "test_dataset = MaskedSequenceDataset(test_sentences, vocab)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m batch_inputs, batch_targets \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[1;32m     22\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m     outputs \u001b[39m=\u001b[39m model(batch_inputs)\n\u001b[1;32m     24\u001b[0m     loss \u001b[39m=\u001b[39m criterion(outputs\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(vocab)), batch_targets\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m     25\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36mFFNN.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m----> 9\u001b[0m     embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding(inputs)\n\u001b[1;32m     10\u001b[0m     hidden \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden(embedded))\n\u001b[1;32m     11\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(hidden)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/sparse.py:160\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    161\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    162\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.hidden = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embedded = self.embedding(inputs)\n",
    "        hidden = torch.relu(self.hidden(embedded))\n",
    "        output = self.output(hidden)\n",
    "        return output\n",
    "\n",
    "\n",
    "model = FFNN(vocab_size=len(vocab), embedding_dim=32, hidden_dim=64)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for batch_inputs, batch_targets in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs.view(-1, len(vocab)), batch_targets.view(-1))\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * batch_inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print('Epoch {} Loss: {:.4f}'.format(epoch, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
