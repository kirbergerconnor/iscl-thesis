{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create corpus (.txt file) for each language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentences(content):\n",
    "    # Remove opening html tag + article title\n",
    "    trimmed_open = re.sub(r'<doc\\b[^>]*>\\s*(?:.*\\n)?', '', content)\n",
    "    # Remove closing html tag\n",
    "    trimmed_close = re.sub(r'<\\/doc\\b[^>]*>', '', trimmed_open)\n",
    "    # Split at periods while trying to overlook abbreviations\n",
    "    return re.split(r'(?<!\\w\\.\\w)(?<!\\w\\.)\\.(?!\\w)', trimmed_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to exclude tree diagrams in wiki\n",
    "# (?<=<doc\\b[^>]*>\\s*(?:.*\\n)?\\n)(.*?)(?=\\n\\n<\\/doc>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with extracted files\n",
    "maindir = '/Users/k/Docs/School/Tuebingen/Thesis/Corpuses/HtmlWiki'\n",
    "wikidirs = [sub for sub in os.listdir(maindir) if sub != '.DS_Store']\n",
    "# Dict of languages + their corresponding alphabets\n",
    "alphabets = {'lfn': re.compile(r'[^a-z]'), 'ia': re.compile(r'[^a-z]'), 'eo': 'abcĉdefgĝhĥijĵklmnoprsŝtuŭvz', 'de': 'abcdefghijklmnopqrstuvwxyzäöüß', 'fr': 'abcdefghijklmnopqrstuvwxyzéàèùëüïâêîôûçæœ', 'en': re.compile(r'[^a-z]')}\n",
    "\n",
    "# Estimated smallest wc (from lfn corpus)\n",
    "min_wc = 1265000\n",
    "\n",
    "for wiki in wikidirs:\n",
    "    wiki_fullpath = os.path.join(maindir, wiki)\n",
    "    lang = os.path.splitext(os.path.basename(wiki))[0].split('_')[0]\n",
    "    current_wc = 0\n",
    "    if lang in alphabets:\n",
    "        alpha = alphabets[lang]\n",
    "    with open(f'/Users/k/Docs/School/Tuebingen/Thesis/iscl-thesis/current_corpora/{lang}_wiki_html.txt', 'w', encoding='utf-8') as out:\n",
    "        for root, dirs, files in os.walk(wiki_fullpath):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                if '/wiki' in file_path:\n",
    "                    with open(file_path) as f: \n",
    "                        content = f.read()\n",
    "                        f.close()\n",
    "                    sentences = clean_sentences(content)\n",
    "                    # Check if alpha in dict is regex\n",
    "                    if isinstance(alpha, re.Pattern):\n",
    "                        for sentence in sentences:\n",
    "                            # Remove Wiki article subheaders\n",
    "                            if len(sentence.split()) > 1:\n",
    "                                # Remove all chars not language's alphabet\n",
    "                                s = ' '.join([re.sub(alpha, '', word.strip().lower()) for word in sentence.split()])\n",
    "                                # Remove leftover whitespaces\n",
    "                                s = re.sub(r'\\s+', ' ', s).strip()\n",
    "                                if (len(s.split()) + current_wc) < min_wc:\n",
    "                                    current_wc += len(s.split())\n",
    "                                    out.write(s + '.' + '\\n')\n",
    "                                else:\n",
    "                                    break\n",
    "                            else:\n",
    "                                continue\n",
    "                    else:\n",
    "                        for sentence in sentences:\n",
    "                            # Remove Wiki article subheaders\n",
    "                            if len(sentence.split()) > 1:\n",
    "                                # Remove all chars not language's alphabet\n",
    "                                s = ' '.join([word.lower() for word in sentence.split() if all(letter in alpha for letter in word.lower())])\n",
    "                                # Remove leftover whitespaces\n",
    "                                s = re.sub(r'\\s+', ' ', s).strip()\n",
    "                                if (len(s.split()) + current_wc) < min_wc:\n",
    "                                    current_wc += len(s.split())\n",
    "                                    out.write(s + '.' + '\\n')\n",
    "                                else:\n",
    "                                    break\n",
    "                            else:\n",
    "                                continue\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
