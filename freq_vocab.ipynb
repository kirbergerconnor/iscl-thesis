{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, re, pandas as pd, numpy as np\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = ['Esperanto.txt', 'Interlingua.txt', 'Lojban.txt', 'Lfn.txt', 'Russian.txt', 'English.txt', 'German.txt', 'Japanese.txt', 'Mandarin.txt', 'Hindi.txt']\n",
    "natural = ['Russian.txt', 'German.txt', 'English.txt', 'Japanese.txt', 'Mandarin.txt', 'Hindi.txt']\n",
    "constructed = ['Esperanto.txt', 'Interlingua.txt', 'Lojban.txt', 'Lfn.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_frequency(corpus):\n",
    "    with open(corpus) as f:\n",
    "        text = f.read().splitlines()\n",
    "        f.close()\n",
    "    df = pd.DataFrame(columns=['Char', 'Act_Freq', 'Rel_Freq', 'Zipf_Freq'])\n",
    "    frequencies = Counter(char for line in text for char in line if char.split())\n",
    "    frequencies = frequencies.most_common()\n",
    "    top_frequency = frequencies[0][1]\n",
    "    \n",
    "    for index, item in enumerate(frequencies, start=1):\n",
    "        relative_freq = \"1/{}\".format(index)\n",
    "        zipf_freq = top_frequency * (1/index)\n",
    "        df.loc[index] = [item[0], item[1], relative_freq, zipf_freq]\n",
    "    # Normalize\n",
    "    # df['Act_Freq'] = preprocessing.minmax_scale(df['Act_Freq'], feature_range=(0.1, 1))\n",
    "    return df\n",
    "\n",
    "\n",
    "def char_vocabulary(corpus=None, df=None):\n",
    "    if corpus:\n",
    "        df = char_frequency(corpus)\n",
    "        return {char: freq for char, freq in zip(df['Char'], df['Act_Freq'])}\n",
    "    return {char: freq for char, freq in zip(df['Char'], df['Act_Freq'])}\n",
    "\n",
    "\n",
    "def plot_char_dist(corpus):\n",
    "    df = char_frequency(corpus)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.ylabel('Zipf Frequency')\n",
    "    plt.xlabel('Char')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.bar(df['Char'], df['Zipf_Freq'])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def obfuscate_text(corpus, vocab):\n",
    "    with open(corpus, 'r', encoding='utf-8') as f:\n",
    "        text = f.read().splitlines()\n",
    "        f.close()\n",
    "    mapping = {value: chr(97 + i) for i, value in enumerate(vocab.values())}\n",
    "    vocab = {k: mapping[v] for k, v in vocab.items()}\n",
    "    table = str.maketrans(vocab)\n",
    "    trans = [line.translate(table) for line in text]\n",
    "    return trans\n",
    "\n",
    "\n",
    "def preprocess_text(corpora):\n",
    "    data = []\n",
    "    for corpus in corpora:\n",
    "        vocab = char_vocabulary(corpus=corpus, df=None)\n",
    "        data += obfuscate_text(corpus, vocab)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_text(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperanto : 300000\n",
      "Interlingua : 1297382\n",
      "Lojban : 16287\n",
      "Lfn : 136241\n",
      "Russian : 100000\n",
      "English : 100000\n",
      "German : 100000\n",
      "Japanese : 100000\n",
      "Mandarin : 100000\n",
      "Hindi : 100000\n"
     ]
    }
   ],
   "source": [
    "def corpus_lengths(corpora):\n",
    "    for file in corpora:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            data = f.read().splitlines()\n",
    "            f.close()\n",
    "        print(f'{file.split(\".\")[0]} : {len(data)}')\n",
    "        \n",
    "corpus_lengths(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperanto : 28\n",
      "Interlingua : 26\n",
      "Lojban : 19\n",
      "Lfn : 26\n",
      "Russian : 50\n",
      "English : 26\n",
      "German : 30\n",
      "Japanese : 3463\n",
      "Mandarin : 8633\n",
      "Hindi : 79\n"
     ]
    }
   ],
   "source": [
    "def vocab_sizes(corpora):\n",
    "    for file in corpora:\n",
    "        vocab = char_vocabulary(corpus=file, df=None)\n",
    "        print(f'{file.split(\".\")[0]} : {len(vocab)}')\n",
    "        \n",
    "vocab_sizes(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def one_hot(data, vocab_size):\n",
    "#     data = data[:100]\n",
    "#     return F.one_hot(data, vocab_size).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
