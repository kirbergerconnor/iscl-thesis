{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, re, glob, string, pandas as pd\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_frequency(corpus):\n",
    "    with open(corpus) as f:\n",
    "        text = f.read().splitlines()\n",
    "    \n",
    "        df = pd.DataFrame(columns=['Char', 'Act_Freq', 'Rel_Freq', 'Zipf_Freq'])\n",
    "        frequencies = Counter(char for line in text for char in line if char.split())\n",
    "        frequencies = frequencies.most_common()\n",
    "        top_frequency = frequencies[0][1]\n",
    "        \n",
    "        for index, item in enumerate(frequencies, start=1):\n",
    "            relative_freq = \"1/{}\".format(index)\n",
    "            zipf_freq = top_frequency * (1/index)\n",
    "            \n",
    "            df.loc[index] = [item[0], item[1], relative_freq, zipf_freq]\n",
    "            \n",
    "        # Normalize\n",
    "        # df['Act_Freq'] = preprocessing.minmax_scale(df['Act_Freq'], feature_range=(0.1, 1))\n",
    "        \n",
    "        f.close()\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def char_vocabulary(df):\n",
    "    return {char: freq for char, freq in zip(df['Char'], df['Act_Freq'])}\n",
    "\n",
    "def plot_char_dist(df):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.ylabel('Zipf Frequency')\n",
    "    plt.xlabel('Char')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.bar(df['Char'], df['Zipf_Freq'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency(corpus):\n",
    "    with open(corpus) as f:\n",
    "        frequencies = Counter([word.lower().strip(exclude) for line in f for word in line.split() if word.strip(exclude)])\n",
    "        \n",
    "        df = pd.DataFrame(columns=['Word', 'Act_Freq', 'Rel_Freq', 'Zipf_Freq'])\n",
    "        frequencies = frequencies.most_common()\n",
    "        top_frequency = frequencies[0][1]\n",
    "        \n",
    "        for index, item in enumerate(frequencies, start=1):\n",
    "            relative_freq = \"1/{}\".format(index)\n",
    "            zipf_freq = top_frequency * (1/index)\n",
    "            \n",
    "            df.loc[index] = [item[0], item[1], relative_freq, zipf_freq]\n",
    "        \n",
    "        f.close()\n",
    "        \n",
    "        # lowest = df[df['Act_Freq'] == 1].index\n",
    "        # df.drop(lowest, inplace=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def word_vocabulary(df):\n",
    "    return {word: freq for word, freq in zip(df['Word'], df['Act_Freq'])}\n",
    "\n",
    "\n",
    "def plot_word_dist(df):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.ylabel('Zipf Frequency')\n",
    "    plt.xlabel('Word')\n",
    "    plt.xticks(rotation=90)\n",
    "    x = df.iloc[:20, df.columns.get_loc('Word')]\n",
    "    y = df.iloc[:20, df.columns.get_loc('Zipf_Freq')]\n",
    "    plt.bar(x, y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obfuscate_text(corpus, vocab):\n",
    "    with open(corpus, 'r', encoding='utf-8') as f:\n",
    "        text = f.read().splitlines()\n",
    "        f.close()\n",
    "    mapping = {value: chr(97 + i) for i, value in enumerate(vocab.values())}\n",
    "    vocab = {k: mapping[v] for k, v in vocab.items()}\n",
    "    table = str.maketrans(vocab)\n",
    "    trans = [line.translate(table) for line in text]\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['Dothraki', 'Lojban', 'LdP', 'LFN', 'Esperanto', 'Interlingua', 'Klingon', 'German', 'English', 'Japanese', 'Russian', 'Chinese', 'Hindi', 'Arabic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join conlang corpora together\n",
    "\n",
    "files = glob.glob('./Data/Conlangs/*.txt')\n",
    "\n",
    "def join_corpora(files):\n",
    "    conlang_dfs = []\n",
    "    for corpus in files:\n",
    "        df = char_frequency(corpus)\n",
    "        conlang_dfs += df               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordToTensor(word):\n",
    "    tensor = torch.zeros(len(word), 1, n_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
