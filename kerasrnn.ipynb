{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Keras RNN with English Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from itertools import chain\n",
    "from keras.layers import Embedding, Dense, LSTM\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "text = open('/Users/k/Docs/School/Tuebingen/Thesis/iscl-thesis/current_corpora/en_wiki_cleaned.txt', 'r', encoding='utf-8').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alphabet in language\n",
    "chars = list(set(chain(*(char for line in text for char in line if line if not char.isspace()))))\n",
    "# Unique set of tokens in text\n",
    "tokens = list(set(chain(*(line.split() for line in text if line))))\n",
    "# BOS char\n",
    "chars.insert(0, '<')\n",
    "# EOS char\n",
    "chars.insert(1, '>')\n",
    "vocab_size = len(chars)\n",
    "max_len = len(max(tokens, key=len))\n",
    "\n",
    "# Make into sequences\n",
    "ch2idx = {c: i for i, c in enumerate(chars)}\n",
    "idx2ch = {i: c for i, c in enumerate(chars)}\n",
    "sequences = [chars[0] + t[::-1] + chars[1] for t in tokens]\n",
    "\n",
    "# Convert to tensors, add padding, split into X_train/y_train and test set\n",
    "X = pad_sequences([[ch2idx[i] for i in seq[:-1]] for seq in sequences])\n",
    "y = pad_sequences([[ch2idx[i] for i in seq[1:]] for seq in sequences])\n",
    "split_index = int(0.8 * len(X))\n",
    "X_train, X_val = X[:split_index], X[split_index:]\n",
    "y_train, y_val = y[:split_index], y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 3\n",
    "loss_function = SparseCategoricalCrossentropy()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "optimizer = Adam()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, mask_zero=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, callbacks=[callback], validation_data=(X_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_perplexity(model, test_data):\n",
    "#     test_sequences = tokenizer.texts_to_sequences(test_data)\n",
    "#     test_sequences = np.array(test_sequences)\n",
    "#     test_sequences = pad_sequences(test_sequences, maxlen=max_sequence_len - 1, padding='pre')\n",
    "#     total_log_loss = 0\n",
    "#     total_words = 0\n",
    "\n",
    "#     for sequence in test_sequences:\n",
    "#         input_seq = sequence[:-1]\n",
    "#         target = sequence[-1]\n",
    "\n",
    "#         predicted = model.predict(input_seq, verbose=0)[0]\n",
    "#         if target != 0:\n",
    "#             total_log_loss += np.log(predicted[int(target)])\n",
    "#             total_words += 1\n",
    "\n",
    "#     avg_log_loss = total_log_loss / total_words\n",
    "#     perplexity = np.exp(-avg_log_loss)\n",
    "#     return perplexity\n",
    "\n",
    "# # Test data for calculating perplexity\n",
    "# test_data = [\"Finally, here is the third sentence.\", \"This is the first sentence.\"]\n",
    "# perplexity = calc_perplexity(model, test_data)\n",
    "# print(f\"Perplexity: {perplexity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
