{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, re\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "from pdfminer.high_level import extract_text_to_fp\n",
    "from pdfminer.layout import LAParams\n",
    "\n",
    "# Humanist Speech PDF\n",
    "output_string = StringIO()\n",
    "with open('humanist_speech_trans.pdf', 'rb') as fin:\n",
    "    extract_text_to_fp(fin, output_string, laparams=LAParams(),\n",
    "                       output_type='html', codec=None)\n",
    "    \n",
    "soup = BeautifulSoup(output_string.getvalue())\n",
    "reg = r\"\\d\\s\\\\n\"\n",
    "text = [sen.get_text().lstrip().replace(\"\\n\", \"\").lower() for sen in soup.find_all(\"span\", style=\"font-family: font00000000296ca43f; font-size:12px\") if \"\\nPage\" not in sen.get_text()]\n",
    "\n",
    "\n",
    "# Animal Farm PDF\n",
    "output_string_2 = StringIO()\n",
    "with open('animal_farm_trans.pdf', 'rb') as f:\n",
    "    extract_text_to_fp(f, output_string_2, laparams=LAParams(),\n",
    "                       output_type='html', codec=None)\n",
    "\n",
    "soup_2 = BeautifulSoup(output_string_2.getvalue())\n",
    "text_2 = [sen.get_text().strip().replace(\"\\n\", \" \").lower() for sen in soup_2.find_all([\"spa\"], style=\"font-family: font00000000296cac0e; font-size:12px\") if \"\\nPage\" not in sen.get_text()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ldp_corpus.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\" \".join(text))\n",
    "    f.write(\" \".join(text_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\"Text\": text})\n",
    "# df.to_csv(\"humanist_speech_text.csv\", index=False, encoding=\"utf-8\")\n",
    "# df_2 = pd.DataFrame({\"Text\": text_2})\n",
    "# df.to_csv(\"animal_farm_text.csv\", index=False, encoding=\"utf-8\")\n",
    "# # Concat both dataframes\n",
    "# ldp_text = pd.concat([df, df_2])\n",
    "# ldp_text.to_csv(\"LdP_text.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# ldp_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
